<tabular xy1="890.73,319.38" xy2="1559.05,1945.89">
	<tr xy1="891.6, 319.38" xy2="1557.96, 387.83">
		<td xy1="891.52, 319.38" xy2="929.05, 387.83" />
		<td xy1="932.32, 319.38" xy2="1558.79, 387.83">Open-Ended Language Generation FAccT ’21, March 3–10, 2021, Virtual Event, Canada</td>
	</tr>
	<tr xy1="892.55, 384.26" xy2="1557.77, 457.17">
		<td xy1="891.52, 384.26" xy2="929.05, 457.17">(2020).[26] Nikita Nangia, C. Vania, Rasika Bhalerao, and Samuel R. Bowman. 2020. CrowS-
Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language
Models. In</td>
		<td xy1="932.32, 384.26" xy2="1558.79, 457.17">(2020).[26] Nikita Nangia, C. Vania, Rasika Bhalerao, and Samuel R. Bowman. 2020. CrowS-
Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language
Models. In EMNLP</td>
	</tr>
	<tr xy1="892.23, 453.98" xy2="1558.0, 545.82">
		<td xy1="891.52, 453.98" xy2="929.05, 545.82"> .
[27] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI
Blog 1, 8 (2019), 9.
</td>
		<td xy1="932.32, 453.98" xy2="1558.79, 545.82">[27] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI
Blog</td>
	</tr>
	<tr xy1="892.97, 547.83" xy2="1557.17, 636.03">
		<td xy1="891.52, 547.83" xy2="929.05, 636.03">[28] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI
Blog 1, 8 (2019), 9.
[29] Rachel Rudinger, Jason Naradowsky, Brian Leonard, and Benjamin Van Durme.
2018. Gender Bias in Coreference Resolution. In</td>
		<td xy1="932.32, 547.83" xy2="1558.79, 636.03">[28] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI
Blog[29] Rachel Rudinger, Jason Naradowsky, Brian Leonard, and Benjamin Van Durme.
2018. Gender Bias in Coreference Resolution. In</td>
	</tr>
	<tr xy1="892.1, 689.82" xy2="1557.91, 752.6">
		<td xy1="891.52, 689.82" xy2="929.05, 752.6">[30] Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2020.
Winogrande: An adversarial winograd schema challenge at scale. In Proceedings
of the AAAI Conference on Artificial Intelligence</td>
		<td xy1="932.32, 689.82" xy2="1558.79, 752.6">[30] Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2020.
Winogrande: An adversarial winograd schema challenge at scale. In Proceedings
of the AAAI Conference on Artificial Intelligence</td>
	</tr>
	<tr xy1="892.46, 735.88" xy2="1557.47, 798.53">
		<td xy1="891.52, 735.88" xy2="929.05, 798.53"> , Vol. 34. 8732–8740.
[31] Emily Sheng, Kai-Wei Chang, Prem Natarajan, and Nanyun Peng. 2019. The
Woman Worked as a Babysitter: On Biases in Language Generation. In Proceedings
</td>
		<td xy1="932.32, 735.88" xy2="1558.79, 798.53">[31] Emily Sheng, Kai-Wei Chang, Prem Natarajan, and Nanyun Peng. 2019. The
Woman Worked as a Babysitter: On Biases in Language Generation. In Proceedings
</td>
	</tr>
	<tr xy1="892.34, 792.65" xy2="1557.56, 862.99">
		<td xy1="891.52, 792.65" xy2="929.05, 862.99"> Proceedings
of the 2019 Conference on Empirical Methods in Natural Language Processing and
the 9th International Joint Conference on Natural Language Processing (EMNLP-
IJCNLP)</td>
		<td xy1="932.32, 792.65" xy2="1558.79, 862.99"> Proceedings
of the 2019 Conference on Empirical Methods in Natural Language Processing and
the 9th International Joint Conference on Natural Language Processing (EMNLP-
IJCNLP)</td>
	</tr>
	<tr xy1="891.62, 842.93" xy2="1558.39, 903.55">
		<td xy1="891.52, 842.93" xy2="929.05, 903.55"> . 3398–3403.
[32] Emily Sheng, Kai-Wei Chang, Prem Natarajan, and Nanyun Peng. 2020. Towards
Controllable Biases in Language Generation. In</td>
		<td xy1="932.32, 842.93" xy2="1558.79, 903.55">[32] Emily Sheng, Kai-Wei Chang, Prem Natarajan, and Nanyun Peng. 2020. Towards
Controllable Biases in Language Generation. In</td>
	</tr>
	<tr xy1="891.85, 843.91" xy2="1558.01, 904.73">
		<td xy1="891.52, 843.91" xy2="929.05, 904.73"> . 3398–3403.
[32] Emily Sheng, Kai-Wei Chang, Prem Natarajan, and Nanyun Peng. 2020. Towards
Controllable Biases in Language Generation. In</td>
		<td xy1="932.32, 843.91" xy2="1558.79, 904.73">[32] Emily Sheng, Kai-Wei Chang, Prem Natarajan, and Nanyun Peng. 2020. Towards
Controllable Biases in Language Generation. In</td>
	</tr>
	<tr xy1="891.06, 883.22" xy2="1558.01, 990.58">
		<td xy1="891.52, 883.22" xy2="929.05, 990.58">[32] Emily Sheng, Kai-Wei Chang, Prem Natarajan, and Nanyun Peng. 2020. Towards
Controllable Biases in Language Generation. In Findings of the Association for
Computational Linguistics: EMNLP 2020 . 3239–3254.
[33] Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai.
2019. VL-BERT: Pre-training of Generic Visual-Linguistic Representations. In
International Conference on Learning Representations</td>
		<td xy1="932.32, 883.22" xy2="1558.79, 990.58">[32] Emily Sheng, Kai-Wei Chang, Prem Natarajan, and Nanyun Peng. 2020. Towards
Controllable Biases in Language Generation. In Findings of the Association for
Computational Linguistics: EMNLP 2020[33] Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai.
2019. VL-BERT: Pre-training of Generic Visual-Linguistic Representations. In
International Conference on Learning Representations</td>
	</tr>
	<tr xy1="891.08, 913.86" xy2="1558.87, 1013.37">
		<td xy1="891.52, 913.86" xy2="929.05, 1013.37"> . 3239–3254.
[33] Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai.
2019. VL-BERT: Pre-training of Generic Visual-Linguistic Representations. In
International Conference on Learning Representations .
</td>
		<td xy1="932.32, 913.86" xy2="1558.79, 1013.37">[33] Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai.
2019. VL-BERT: Pre-training of Generic Visual-Linguistic Representations. In
International Conference on Learning Representations</td>
	</tr>
	<tr xy1="891.69, 1107.44" xy2="1558.11, 1231.81">
		<td xy1="891.52, 1107.44" xy2="929.05, 1231.81">
Proceedings of the 57th Annual Meeting of the Association for Computational
Linguistics . 1630–1640.
[36] Claudia Wagner, David Garcia, Mohsen Jadidi, and Markus Strohmaier. 2015. It’s
a Man’s Wikipedia? Assessing Gender Inequality in an Online Encyclopedia. In
International AAAI Conference on Weblogs and Social Media</td>
		<td xy1="932.32, 1107.44" xy2="1558.79, 1231.81">
Proceedings of the 57th Annual Meeting of the Association for Computational
Linguistics[36] Claudia Wagner, David Garcia, Mohsen Jadidi, and Markus Strohmaier. 2015. It’s
a Man’s Wikipedia? Assessing Gender Inequality in an Online Encyclopedia. In
International AAAI Conference on Weblogs and Social Media</td>
	</tr>
	<tr xy1="891.87, 1201.98" xy2="1558.77, 1283.02">
		<td xy1="891.52, 1201.98" xy2="929.05, 1283.02">
International AAAI Conference on Weblogs and Social Media . USA, 454–463.
[37] Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019.
Universal Adversarial Triggers for Attacking and Analyzing NLP. In</td>
		<td xy1="932.32, 1201.98" xy2="1558.79, 1283.02">
International AAAI Conference on Weblogs and Social Media[37] Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019.
Universal Adversarial Triggers for Attacking and Analyzing NLP. In</td>
	</tr>
	<tr xy1="891.96, 1246.76" xy2="1558.4, 1330.49">
		<td xy1="891.52, 1246.76" xy2="929.05, 1330.49">[37] Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019.
Universal Adversarial Triggers for Attacking and Analyzing NLP. In Proceedings
of the 2019 Conference on Empirical Methods in Natural Language Processing and
the 9th International Joint Conference on Natural Language Processing (EMNLP-
IJCNLP)</td>
		<td xy1="932.32, 1246.76" xy2="1558.79, 1330.49">[37] Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019.
Universal Adversarial Triggers for Attacking and Analyzing NLP. In Proceedings
of the 2019 Conference on Empirical Methods in Natural Language Processing and
the 9th International Joint Conference on Natural Language Processing (EMNLP-
IJCNLP)</td>
	</tr>
	<tr xy1="892.05, 1304.11" xy2="1558.26, 1396.27">
		<td xy1="891.52, 1304.11" xy2="929.05, 1396.27">of the 2019 Conference on Empirical Methods in Natural Language Processing and
the 9th International Joint Conference on Natural Language Processing (EMNLP-
IJCNLP) . 2153–2162.
[38] Alex Wang and Kyunghyun Cho. 2019. BERT has a Mouth, and It Must Speak:
BERT as a Markov Random Field Language Model. In Proceedings of the Workshop
on Methods for Optimizing and Evaluating Neural Language Generation</td>
		<td xy1="932.32, 1304.11" xy2="1558.79, 1396.27">of the 2019 Conference on Empirical Methods in Natural Language Processing and
the 9th International Joint Conference on Natural Language Processing (EMNLP-
IJCNLP)[38] Alex Wang and Kyunghyun Cho. 2019. BERT has a Mouth, and It Must Speak:
BERT as a Markov Random Field Language Model. In Proceedings of the Workshop
on Methods for Optimizing and Evaluating Neural Language Generation</td>
	</tr>
	<tr xy1="891.42, 1361.55" xy2="1558.48, 1486.99">
		<td xy1="891.52, 1361.55" xy2="929.05, 1486.99">[38] Alex Wang and Kyunghyun Cho. 2019. BERT has a Mouth, and It Must Speak:
BERT as a Markov Random Field Language Model. In Proceedings of the Workshop
on Methods for Optimizing and Evaluating Neural Language Generation . 30–36.
[39] Qingyun Wang, Lifu Huang, Zhiying Jiang, Kevin Knight, Heng Ji, Mohit Bansal,
and Yi Luan. 2019. PaperRobot: Incremental Draft Generation of Scientific Ideas.
InProceedings of the 57th Annual Meeting of the Association for Computational
Linguistics</td>
		<td xy1="932.32, 1361.55" xy2="1558.79, 1486.99">[38] Alex Wang and Kyunghyun Cho. 2019. BERT has a Mouth, and It Must Speak:
BERT as a Markov Random Field Language Model. In Proceedings of the Workshop
on Methods for Optimizing and Evaluating Neural Language Generation[39] Qingyun Wang, Lifu Huang, Zhiying Jiang, Kevin Knight, Heng Ji, Mohit Bansal,
and Yi Luan. 2019. PaperRobot: Incremental Draft Generation of Scientific Ideas.
InProceedings of the 57th Annual Meeting of the Association for Computational
Linguistics</td>
	</tr>
	<tr xy1="891.61, 1476.07" xy2="1558.4, 1576.88">
		<td xy1="891.52, 1476.07" xy2="929.05, 1576.88">Proceedings of the 57th Annual Meeting of the Association for Computational
Linguistics . 1980–1991.
[40] K. Webster, M. Recasens, Vera Axelrod, and Jason Baldridge. 2018. Mind the
GAP: A Balanced Corpus of Gendered Ambiguous Pronouns. Transactions of the
Association for Computational Linguistics 6 (2018), 605–617.
</td>
		<td xy1="932.32, 1476.07" xy2="1558.79, 1576.88">Proceedings of the 57th Annual Meeting of the Association for Computational
Linguistics[40] K. Webster, M. Recasens, Vera Axelrod, and Jason Baldridge. 2018. Mind the
GAP: A Balanced Corpus of Gendered Ambiguous Pronouns. Transactions of the
Association for Computational Linguistics</td>
	</tr>
	<tr xy1="892.11, 1605.58" xy2="1557.77, 1697.65">
		<td xy1="891.52, 1605.58" xy2="929.05, 1697.65">https://en.wikipedia.org/w/index.php?title=Plagiarism&amp;oldid=5139350 [Online;
accessed 22-July-2004].
[42] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe
</td>
		<td xy1="932.32, 1605.58" xy2="1558.79, 1697.65">https://en.wikipedia.org/w/index.php?title=Plagiarism&amp;oldid=5139350 [Online;
[42] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe
</td>
	</tr>
	<tr xy1="892.36, 1688.15" xy2="1557.1, 1764.99">
		<td xy1="891.52, 1688.15" xy2="929.05, 1764.99">Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu,
Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
and Alexander M. Rush. 2020. HuggingFace’s Transformers: State-of-the-art
Natural Language Processing. In</td>
		<td xy1="932.32, 1688.15" xy2="1558.79, 1764.99">Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu,
Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
and Alexander M. Rush. 2020. HuggingFace’s Transformers: State-of-the-art
Natural Language Processing. In EMNLP</td>
	</tr>
	<tr xy1="891.15, 1762.21" xy2="1557.38, 1872.6">
		<td xy1="891.52, 1762.21" xy2="929.05, 1872.6"> .
[43] Lili Yao, Nanyun Peng, Ralph Weischedel, Kevin Knight, Dongyan Zhao, and Rui
Yan. 2019. Plan-and-write: Towards better automatic storytelling. In Proceedings
of the AAAI Conference on Artificial Intelligence , Vol. 33. 7378–7385.
[44] Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti,
</td>
		<td xy1="932.32, 1762.21" xy2="1558.79, 1872.6">[43] Lili Yao, Nanyun Peng, Ralph Weischedel, Kevin Knight, Dongyan Zhao, and Rui
Yan. 2019. Plan-and-write: Towards better automatic storytelling. In Proceedings
of the AAAI Conference on Artificial Intelligence[44] Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti,
</td>
	</tr>
	<tr xy1="890.73, 1867.66" xy2="1559.05, 1945.89">
		<td xy1="891.52, 1867.66" xy2="929.05, 1945.89">Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, et al .
2020. Big bird: Transformers for longer sequences. (2020), accepted.
[45] Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang.
</td>
		<td xy1="932.32, 1867.66" xy2="1558.79, 1945.89">Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, et al .
[45] Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang.
</td>
	</tr>
</tabular>